{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boston  (379, 14)\n",
      "boston_test  (127, 13)\n",
      "input  (379, 13)\n",
      "Y  (379,)\n",
      "transformed input : (379, 13)\n",
      "input afet appending Y & 1 : (379, 15)\n",
      "Cost  0   372.6402282491625\n",
      "Cost  1   246.0806844988687\n",
      "Cost  2   166.3146252952613\n",
      "Cost  3   115.50146384046272\n",
      "Cost  4   83.05871412434604\n",
      "Cost  5   62.30835093474387\n",
      "Cost  6   49.01041492738445\n",
      "Cost  7   40.46819132006823\n",
      "Cost  8   34.96435757451735\n",
      "Cost  9   31.40411193003393\n",
      "Cost  10   29.088839619508146\n",
      "Cost  11   27.57233914482174\n",
      "Cost  12   26.569371917610468\n",
      "Cost  13   25.897428428927448\n",
      "Cost  14   25.439610994540985\n",
      "Cost  15   25.120956642829356\n",
      "Cost  16   24.893322775748782\n",
      "Cost  17   24.72573279388676\n",
      "Cost  18   24.59820571807398\n",
      "Cost  19   24.497810335880736\n",
      "Cost  20   24.416140489513502\n",
      "Cost  21   24.347698718421235\n",
      "Cost  22   24.288860770386076\n",
      "Cost  23   24.237211732207697\n",
      "Cost  24   24.191120020119126\n",
      "Cost  25   24.149463690506025\n",
      "Cost  26   24.11145434709487\n",
      "Cost  27   24.076523621503288\n",
      "Cost  28   24.04424980351434\n",
      "Cost  29   24.014310258104167\n",
      "Cost  30   23.986450424888826\n",
      "Cost  31   23.960463498173404\n",
      "Cost  32   23.936177000775878\n",
      "Cost  33   23.913443819799046\n",
      "Cost  34   23.892136141002045\n",
      "Cost  35   23.872141275354995\n",
      "Cost  36   23.853358728725954\n",
      "Cost  37   23.83569809513467\n",
      "Cost  38   23.81907750151465\n",
      "Cost  39   23.803422426857885\n",
      "Cost  40   23.788664779806147\n",
      "Cost  41   23.774742158279512\n",
      "Cost  42   23.76159724033002\n",
      "Cost  43   23.749177272046953\n",
      "Cost  44   23.737433629202133\n",
      "Cost  45   23.726321436459465\n",
      "Cost  46   23.715799232694742\n",
      "Cost  47   23.705828674127254\n",
      "Cost  48   23.696374269100207\n",
      "Cost  49   23.68740313981209\n",
      "Cost  50   23.678884807325918\n",
      "Cost  51   23.670790996913794\n",
      "Cost  52   23.66309546132732\n",
      "Cost  53   23.655773819982596\n",
      "Cost  54   23.6488034123551\n",
      "Cost  55   23.642163164117626\n",
      "Cost  56   23.63583346474814\n",
      "Cost  57   23.629796055491276\n",
      "Cost  58   23.624033926689034\n",
      "Cost  59   23.618531223605842\n",
      "Cost  60   23.613273159970525\n",
      "Cost  61   23.60824593853693\n",
      "Cost  62   23.603436678039532\n",
      "Cost  63   23.598833345980612\n",
      "Cost  64   23.5944246967425\n",
      "Cost  65   23.590200214567496\n",
      "Cost  66   23.58615006098997\n",
      "Cost  67   23.58226502634671\n",
      "Cost  68   23.578536485023708\n",
      "Cost  69   23.5749563541305\n",
      "Cost  70   23.57151705532049\n",
      "Cost  71   23.568211479500476\n",
      "Cost  72   23.565032954196237\n",
      "Cost  73   23.561975213360306\n",
      "Cost  74   23.559032369427385\n",
      "Cost  75   23.556198887439585\n",
      "Cost  76   23.553469561077865\n",
      "Cost  77   23.550839490450898\n",
      "Cost  78   23.548304061504968\n",
      "Cost  79   23.545858926928386\n",
      "Cost  80   23.54349998843685\n",
      "Cost  81   23.541223380332664\n",
      "Cost  82   23.539025454241916\n",
      "Cost  83   23.53690276493944\n",
      "Cost  84   23.534852057180238\n",
      "Cost  85   23.532870253461276\n",
      "Cost  86   23.530954442644017\n",
      "Cost  87   23.529101869374543\n",
      "Cost  88   23.527309924240583\n",
      "Cost  89   23.525576134612724\n",
      "Cost  90   23.523898156118126\n",
      "Cost  91   23.522273764701072\n",
      "Cost  92   23.520700849227772\n",
      "Cost  93   23.519177404595226\n",
      "Cost  94   23.517701525307817\n",
      "Cost  95   23.51627139948836\n",
      "Cost  96   23.51488530329179\n",
      "Cost  97   23.513541595692896\n",
      "Cost  98   23.512238713621375\n",
      "Cost  99   23.510975167419524\n",
      "Cost  100   23.509749536599585\n",
      "Cost  101   23.508560465879818\n",
      "Cost  102   23.50740666147924\n",
      "Cost  103   23.506286887653477\n",
      "Cost  104   23.50519996345422\n",
      "Cost  105   23.504144759697382\n",
      "Cost  106   23.503120196124843\n",
      "Cost  107   23.502125238746828\n",
      "Cost  108   23.501158897352152\n",
      "Cost  109   23.50022022317515\n",
      "Cost  110   23.499308306708297\n",
      "Cost  111   23.49842227565052\n",
      "Cost  112   23.49756129298236\n",
      "Cost  113   23.496724555158995\n",
      "Cost  114   23.495911290413357\n",
      "Cost  115   23.49512075716201\n",
      "Cost  116   23.494352242506764\n",
      "Cost  117   23.49360506082581\n",
      "Cost  118   23.492878552448158\n",
      "Cost  119   23.492172082406263\n",
      "Cost  120   23.491485039261377\n",
      "Cost  121   23.49081683399711\n",
      "Cost  122   23.49016689897625\n",
      "Cost  123   23.489534686957555\n",
      "Cost  124   23.488919670168034\n",
      "Cost  125   23.488321339426985\n",
      "Cost  126   23.487739203319208\n",
      "Cost  127   23.48717278741374\n",
      "Cost  128   23.4866216335251\n",
      "Cost  129   23.48608529901485\n",
      "Cost  130   23.485563356130456\n",
      "Cost  131   23.48505539137971\n",
      "Cost  132   23.4845610049376\n",
      "Cost  133   23.48407981008471\n",
      "Cost  134   23.483611432674337\n",
      "Cost  135   23.483155510626997\n",
      "Cost  136   23.482711693450682\n",
      "Cost  137   23.482279641785098\n",
      "Cost  138   23.481859026968554\n",
      "Cost  139   23.48144953062627\n",
      "Cost  140   23.481050844278673\n",
      "Cost  141   23.48066266896855\n",
      "Cost  142   23.480284714906023\n",
      "Cost  143   23.47991670113026\n",
      "Cost  144   23.479558355187034\n",
      "Cost  145   23.47920941282101\n",
      "Cost  146   23.47886961768235\n",
      "Cost  147   23.47853872104632\n",
      "Cost  148   23.47821648154553\n",
      "Cost  149   23.477902664914065\n",
      "Cost  150   23.477597043742705\n",
      "Cost  151   23.477299397244877\n",
      "Cost  152   23.47700951103232\n",
      "Cost  153   23.476727176900535\n",
      "Cost  154   23.476452192623203\n",
      "Cost  155   23.476184361754843\n",
      "Cost  156   23.475923493441705\n",
      "Cost  157   23.475669402240474\n",
      "Cost  158   23.47542190794391\n",
      "Cost  159   23.475180835413614\n",
      "Cost  160   23.474946014419345\n",
      "Cost  161   23.47471727948444\n",
      "Cost  162   23.47449446973719\n",
      "Cost  163   23.474277428768\n",
      "Cost  164   23.47406600449176\n",
      "Cost  165   23.473860049015336\n",
      "Cost  166   23.47365941850998\n",
      "Cost  167   23.47346397308856\n",
      "Cost  168   23.473273576686758\n",
      "Cost  169   23.473088096949084\n",
      "Cost  170   23.472907405118328\n",
      "Cost  171   23.472731375929513\n",
      "Cost  172   23.472559887506947\n",
      "Cost  173   23.472392821265327\n",
      "Cost  174   23.472230061813615\n",
      "Cost  175   23.472071496862938\n",
      "Cost  176   23.471917017136803\n",
      "Cost  177   23.471766516284756\n",
      "Cost  178   23.471619890798852\n",
      "Cost  179   23.471477039932598\n",
      "Cost  180   23.471337865622868\n",
      "Cost  181   23.47120227241401\n",
      "Cost  182   23.47107016738455\n",
      "Cost  183   23.470941460076332\n",
      "Cost  184   23.470816062425506\n",
      "Cost  185   23.470693888696125\n",
      "Cost  186   23.47057485541536\n",
      "Cost  187   23.470458881311206\n",
      "Cost  188   23.47034588725157\n",
      "Cost  189   23.47023579618561\n",
      "Cost  190   23.470128533086694\n",
      "Cost  191   23.470024024897057\n",
      "Cost  192   23.469922200474073\n",
      "Cost  193   23.46982299053834\n",
      "Cost  194   23.46972632762304\n",
      "Cost  195   23.46963214602486\n",
      "Cost  196   23.469540381756467\n",
      "Cost  197   23.469450972500304\n",
      "Cost  198   23.469363857563597\n",
      "Cost  199   23.46927897783482\n",
      "Cost  200   23.469196275741428\n",
      "Cost  201   23.46911569520851\n",
      "Cost  202   23.469037181619075\n",
      "Cost  203   23.468960681775087\n",
      "Cost  204   23.468886143859773\n",
      "Cost  205   23.468813517400868\n",
      "Cost  206   23.468742753235176\n",
      "Cost  207   23.46867380347363\n",
      "Cost  208   23.468606621467885\n",
      "Cost  209   23.46854116177735\n",
      "Cost  210   23.468477380137497\n",
      "Cost  211   23.46841523342887\n",
      "Cost  212   23.46835467964683\n",
      "Cost  213   23.468295677872394\n",
      "Cost  214   23.46823818824377\n",
      "Cost  215   23.468182171928543\n",
      "Cost  216   23.46812759109676\n",
      "Cost  217   23.46807440889474\n",
      "Cost  218   23.46802258941944\n",
      "Cost  219   23.467972097693693\n",
      "Cost  220   23.467922899642215\n",
      "Cost  221   23.46787496206768\n",
      "Cost  222   23.46782825262835\n",
      "Cost  223   23.467782739815288\n",
      "Cost  224   23.467738392931096\n",
      "Cost  225   23.467695182068642\n",
      "Cost  226   23.4676530780905\n",
      "Cost  227   23.467612052609105\n",
      "Cost  228   23.46757207796709\n",
      "Cost  229   23.46753312721854\n",
      "Cost  230   23.467495174110397\n",
      "Cost  231   23.467458193064683\n",
      "Cost  232   23.467422159160822\n",
      "Cost  233   23.467387048118812\n",
      "Cost  234   23.467352836282494\n",
      "Cost  235   23.467319500603487\n",
      "Cost  236   23.46728701862561\n",
      "Cost  237   23.467255368469257\n",
      "Cost  238   23.467224528816857\n",
      "Cost  239   23.467194478898218\n",
      "Cost  240   23.46716519847627\n",
      "Cost  241   23.467136667833632\n",
      "Cost  242   23.46710886775874\n",
      "Cost  243   23.467081779533373\n",
      "Cost  244   23.46705538491951\n",
      "Cost  245   23.467029666147095\n",
      "Cost  246   23.467004605901934\n",
      "Cost  247   23.466980187314114\n",
      "Cost  248   23.46695639394645\n",
      "Cost  249   23.46693320978325\n",
      "Cost  250   23.466910619219618\n",
      "Cost  251   23.466888607050883\n",
      "Cost  252   23.466867158462207\n",
      "Cost  253   23.46684625901868\n",
      "Cost  254   23.466825894655393\n",
      "Cost  255   23.466806051668083\n",
      "Cost  256   23.466786716703787\n",
      "Cost  257   23.46676787675181\n",
      "Cost  258   23.46674951913498\n",
      "Cost  259   23.466731631501034\n",
      "Cost  260   23.466714201814284\n",
      "Cost  261   23.466697218347438\n",
      "Cost  262   23.46668066967382\n",
      "Cost  263   23.46666454465957\n",
      "Cost  264   23.46664883245602\n",
      "Cost  265   23.466633522492593\n",
      "Cost  266   23.466618604469417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost  267   23.46660406835067\n",
      "Cost  268   23.466589904357523\n",
      "Cost  269   23.466576102961717\n",
      "Cost  270   23.466562654879095\n",
      "Cost  271   23.46654955106328\n",
      "Cost  272   23.466536782699695\n",
      "Cost  273   23.46652434119951\n",
      "Cost  274   23.466512218193873\n",
      "Cost  275   23.466500405528343\n",
      "Cost  276   23.46648889525735\n",
      "Cost  277   23.466477679638718\n",
      "Cost  278   23.46646675112875\n",
      "Cost  279   23.466456102376714\n",
      "Cost  280   23.466445726220325\n",
      "Cost  281   23.46643561568066\n",
      "Cost  282   23.466425763957496\n",
      "Cost  283   23.466416164424828\n",
      "Cost  284   23.466406810626193\n",
      "Cost  285   23.46639769627064\n",
      "Cost  286   23.466388815228214\n",
      "Cost  287   23.466380161525908\n",
      "Cost  288   23.466371729343745\n",
      "Cost  289   23.466363513010684\n",
      "Cost  290   23.466355507000927\n",
      "Cost  291   23.46634770593027\n",
      "Cost  292   23.466340104552188\n",
      "Cost  293   23.46633269775463\n",
      "Cost  294   23.46632548055636\n",
      "Cost  295   23.46631844810377\n",
      "Cost  296   23.46631159566742\n",
      "Cost  297   23.466304918638965\n",
      "Cost  298   23.466298412528168\n",
      "Cost  299   23.466292072959654\n",
      "(14,)\n",
      "(127, 13)\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def step_gradient(data,lr,m):\n",
    "    N = len(data)\n",
    "    n = len(m)\n",
    "    m_slope = np.zeros(n)\n",
    "    m_new = np.zeros(n)\n",
    "    for i in range(N):\n",
    "        a = np.dot(m,data[i][:-1])\n",
    "        for j in range(n):\n",
    "            x = data[i,j]\n",
    "            y = data[i,n]\n",
    "            m_slope[j] += (-2/N)*(y-a)*x\n",
    "            m_new[j] = m[j]-lr*m_slope[j]\n",
    "    return m_new\n",
    "\n",
    "\n",
    "def cost(data,m):\n",
    "    total_cost = 0\n",
    "    N = len(data)\n",
    "    n = len(m)\n",
    "    for i in range(N):\n",
    "        a = np.dot(m,data[i][:-1])\n",
    "        y = data[i,n]\n",
    "        total_cost += (1/N)*((y-a)**2)\n",
    "    return total_cost\n",
    "\n",
    "def gd(data,lr,ni):\n",
    "    m=np.zeros(len(data[0][:-1]))\n",
    "    for i in range(ni):\n",
    "        m = step_gradient(data,lr,m)\n",
    "        print(\"Cost \",i, \" \", cost(data,m))\n",
    "    return m\n",
    "\n",
    "def predict(m,test_data):\n",
    "    c = m[-1]\n",
    "    m = m[:-1]\n",
    "    Y_pred = []\n",
    "    for i in range(len(test_data)):\n",
    "        Y_pred.append(np.dot(test_data[i],m))\n",
    "        Y_pred[i] += c\n",
    "    return Y_pred\n",
    "\n",
    "def run():\n",
    "    boston = np.loadtxt(\"C:/Users/Dhruv/Desktop/Machine Learning/Datasets/Boston/0000000000002417_training_boston_x_y_train.csv\", delimiter = \",\")\n",
    "    boston_test = np.loadtxt(\"C:/Users/Dhruv/Desktop/Machine Learning/Datasets/Boston/0000000000002417_test_boston_x_test.csv\", delimiter = \",\")\n",
    "    print(\"boston \",boston.shape)\n",
    "    X = boston\n",
    "#     X = np.insert(boston,-1,1,axis=1)\n",
    "#     boston_test = np.insert(boston_test,-1,1,axis=1)\n",
    "    print(\"boston_test \",boston_test.shape)\n",
    "#     print(\"X (after inserting 1) \",X.shape)\n",
    "    # print(X)\n",
    "#     df = pd.DataFrame(X)\n",
    "#     df.columns  = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX','PTRATIO', 'B', 'LSTAT','C','Y']\n",
    "    scalar = preprocessing.StandardScaler()\n",
    "    # print(X[:,:-1].shape)\n",
    "    input = X[:,:-1]\n",
    "    Y = X[:,-1]\n",
    "    print(\"input \",input.shape)\n",
    "    print(\"Y \" ,Y.shape)\n",
    "    scalar.fit(input)\n",
    "    lr = 0.1\n",
    "    ni = 300\n",
    "    input = scalar.transform(input)\n",
    "    print(\"transformed input :\", input.shape)\n",
    "    \n",
    "    Y = Y.tolist()\n",
    "    input = input.tolist()\n",
    "    for i in range(len(input)):\n",
    "        input[i].append(Y[i])\n",
    "    input = np.array(input)\n",
    "    Y = np.array(Y)\n",
    "    input = np.insert(input,-1,1,axis=1)\n",
    "    print(\"input afet appending Y & 1 :\",input.shape)\n",
    "    m = gd(input,lr,ni)\n",
    "    print(m.shape)\n",
    "    boston_test = scalar.transform(boston_test)\n",
    "    print(boston_test.shape)\n",
    "#     boston_test = np.insert(boston_test,-1,1,axis=1)\n",
    "#     print(\"boston_test after appending 1 :\", boston_test.shape)\n",
    "    Y_final = predict(m,boston_test)\n",
    "    print(len(Y_final))\n",
    "#     print(Y_final)\n",
    "    np.savetxt(\"C:/Users/Dhruv/Desktop/Machine Learning/Datasets/Boston/predictions.csv\",Y_final)\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
